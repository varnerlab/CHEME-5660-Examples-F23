abstract type AbstractSamplingModel end

mutable struct EpsilonSamplingModel <: AbstractSamplingModel

    # data -
    Î±::Array{Float64,1}
    Î²::Array{Float64,1}
    K::Int64
    Ïµ::Float64

    # constructor -
    EpsilonSamplingModel() = new();
end


function sample(model::EpsilonSamplingModel, data::Dict{String,DataFrame}, tickers::Array{String,1}; ð’¯::Int64 = 0)

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Ïµ = model.Ïµ
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict_Ts = Dict{Int64, Array{Float64,2}}();

    # generate random Categorical distribution -
    parray = [1/K for i = 1:K]
    dcat = Categorical(parray);
    
    # initialize collection of Beta distributions -
    action_distribution = Array{Beta,1}(undef, K);
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end
 
    # main sampling loop -
    for t âˆˆ 1:ð’¯

        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K, 2);
        fill!(parameter_array, 0.0);

        for k âˆˆ 1:K
            
            # grab the distribution for action k -
            d = action_distribution[k];

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict_Ts[t] = parameter_array;
        end

        aâ‚œ = 1; # default to 1
        if (rand() < Ïµ)
            aâ‚œ = rand(dcat);
        else
            
            for k âˆˆ 1:K

                # grab the distribution for action k -
                d = action_distribution[k];
    
                # generate a sample for this action -
                Î¸Ì‚_vector[k] = rand(d);
            end

            # ok: let's choose an action -
            aâ‚œ = argmax(Î¸Ì‚_vector);

            # pass that action to the world function, gives back a reward -
            râ‚œ = _world(aâ‚œ, t, data, tickers);


            # update the parameters -
            # first, get the old parameters -
            old_d = action_distribution[aâ‚œ];
            Î±â‚’,Î²â‚’ = params(old_d);

            # update the old values with the new values -
            Î±â‚œ = Î±â‚’ + râ‚œ
            Î²â‚œ = Î²â‚’ + (1-râ‚œ)

            # @show (aâ‚œ, râ‚œ,  Î±â‚’, Î²â‚’, Î±â‚œ, Î²â‚œ)

            # build new distribution -
            action_distribution[aâ‚œ] = Beta(Î±â‚œ, Î²â‚œ);
        end
    end

    return time_sample_results_dict_Ts;
end

function sample(model::EpsilonSamplingModel, world::Function, data::Dict{String,DataFrame}, tickers::Array{String,1}; 
    horizon::Int64 = 100, buffersize::Int64 = 1, risk_free_rate::Float64 = 0.05)

    # initialize -
    Î± = model.Î±
    Î² = model.Î²
    K = model.K
    Ïµ = model.Ïµ
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    time_sample_results_dict_Ts = Dict{Int64, Array{Float64,2}}();
    action_distribution = Array{Beta,1}(undef, K);

    # generate random Categorical distribution -
    parray = [1/K for _ = 1:K]
    dcat = Categorical(parray);
    
    # initialize collection of Beta distributions -
    for k âˆˆ 1:K
        action_distribution[k] = Beta(Î±[k], Î²[k]); # initialize uniform
    end
 
    # main sampling loop -
    for t âˆˆ 1:horizon

        # create a new parameter array -
        parameter_array = Array{Float64,2}(undef, K, 2);
        fill!(parameter_array, 0.0);

        # for each action, grab the parameters -
        for k âˆˆ 1:K
            
            # grab the distribution for action k -
            d = action_distribution[k];

            # store the parameter array -
            Î±â‚–, Î²â‚– = params(d);
            parameter_array[k,1] = Î±â‚–
            parameter_array[k,2] = Î²â‚–

            # store -
            time_sample_results_dict_Ts[t] = parameter_array;
        end

        aâ‚œ = nothing; # default to 1
        if (rand() < Ïµ)
            aâ‚œ = rand(dcat); # choose a random action uniformly
        else
            
            for k âˆˆ 1:K

                # grab the distribution for action k -
                d = action_distribution[k];
    
                # generate a sample for this action -
                Î¸Ì‚_vector[k] = rand(d);
            end

            # ok: let's choose an action -
            aâ‚œ = argmax(Î¸Ì‚_vector);

            # pass that action to the world function, gives back a reward -
            râ‚œ = world(aâ‚œ, t, data, tickers; buffersize = buffersize, risk_free_rate = risk_free_rate);

            # update the parameters -
            # first, get the old parameters -
            old_d = action_distribution[aâ‚œ];
            Î±â‚’,Î²â‚’ = params(old_d);

            # update the old values with the new values -
            Î±â‚œ = Î±â‚’ + râ‚œ
            Î²â‚œ = Î²â‚’ + (1-râ‚œ)

            # build new distribution -
            action_distribution[aâ‚œ] = Beta(Î±â‚œ, Î²â‚œ);
        end
    end

    return time_sample_results_dict_Ts;
end


function build_beta_array(parameters::Array{Float64,2})::Array{Beta,1}

    # build an array of beta distributions -
    (NR,_) = size(parameters);
    beta_array = Array{Beta,1}(undef,NR)
    for i âˆˆ 1:NR
        
        # grab the parameters -
        Î± = parameters[i,1];
        Î² = parameters[i,2];

        # build -
        beta_array[i] = Beta(Î±, Î²);
    end

    # return -
    return beta_array;
end

function preference(beta::Array{Beta,1}, tickers::Array{String,1}; N::Int64 = 100)

    # sample -
    K = length(tickers);
    tmp_array = Array{Int64,1}(undef, N);
    Î¸Ì‚_vector = Array{Float64,1}(undef, K)
    pref_array = Array{Float64,1}(undef, K)

    # main sampling loop -
    # for i âˆˆ 1:N # for each sample
    #     for k âˆˆ 1:K # for each action
            
    #         # grab -
    #         d = beta[k];
            
    #         # generate a sample for this action -
    #         Î¸Ì‚_vector[k] = rand(d);
    #     end

    #     # ok: let's choose an action -
    #     tmp_array[i] = argmax(Î¸Ì‚_vector);
    # end

    # Let's compute the mean of each beta distribution -
    for k âˆˆ 1:K # for each action
        
        # grab -
        d = beta[k];
        Î±,Î² = params(d);
        
        # generate a sample for this action -
        Î¸Ì‚_vector[k] = (Î±)/(Î±+Î²);
    end

    # ok: let's choose an action -


    # # how many of each do we have?
    # for k âˆˆ 1:K
    #     idx = findall(x->x==k, tmp_array);
    #     pref_array[k] = length(idx)/N;
    # end

    # return -
    return tiedrank(Î¸Ì‚_vector, rev = true);
end
